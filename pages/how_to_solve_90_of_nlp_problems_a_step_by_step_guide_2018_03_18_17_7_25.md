<a href="https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e">https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e</a><div id="articleHeader"><h1><strong>How to solve 90% of NLP problems: a step-by-step guide</strong></h1></div><h2 id="e32c"><strong>Using Machine Learning to understand and leverage text.</strong></h2><div><figure id="376e"><div><div><div class="readableLargeImageContainer"><img src="https://cdn-images-1.medium.com/max/2000/1*J8-5VgoWtMsIJhyHAuljSw.png" /></div><figcaption>How you can apply the 5 W’s and H to Text Data!</figcaption></figure><div><p id="be56"><em>For more content like this, follow </em><a href="https://twitter.com/InsightDataSci" target="_blank"><em>Insight</em></a><em> and </em><a href="https://twitter.com/EmmanuelAmeisen" target="_blank"><em>Emmanuel</em></a><em> on Twitter.</em></p><h3 id="6cd0">Text data is everywhere</h3><p id="f7ea">Whether you are an established company or working to launch a new service, you can always leverage text data to validate, improve, and expand the functionalities of your product. The science of extracting meaning and learning from text data is an active topic of research called Natural Language Processing (NLP).</p><p id="97ce">NLP produces <a href="https://arxiv.org/abs/1704.01444" target="_blank">new</a> and <a href="https://arxiv.org/abs/1711.00043" target="_blank">exciting</a> <a href="https://arxiv.org/abs/1708.04729" target="_blank">results</a> on a daily basis, and is a very large field. However, having worked with hundreds of companies, the Insight team has seen a few key practical applications come up much more frequently than any other:</p><p id="f5d4">While many NLP papers and tutorials exist online, we have found it hard to find guidelines and tips on how to approach these problems <strong>efficiently </strong>from the ground up.</p><h3 id="3acd">How this article can help</h3><p id="98c7">After leading hundreds of projects a year and gaining advice from top teams all over the United States, we wrote this post to explain how to build Machine Learning solutions to solve problems like the ones mentioned above. We’ll begin with <strong>the simplest method</strong> that could work, and then move on to more nuanced solutions, such as feature engineering, word vectors, and deep learning.</p><p id="b8b4">After reading this article, you’ll know how to:</p><p id="74e7">We wrote this post as a step-by-step guide; it can also serve as a high level overview of highly effective standard approaches.</p></div></section><p id="e097"><strong><em>This post is accompanied by </em></strong><a href="https://github.com/hundredblocks/concrete_NLP_tutorial/blob/master/NLP_notebook.ipynb" target="_blank"><strong><em>an interactive notebook</em></strong></a><strong><em> demonstrating and applying all these techniques. Feel free to run the code and follow along!</em></strong></p><h3 id="3693">Step 1: Gather your data</h3><h4 id="faf5">Example data sources</h4><p id="f3e1">Every Machine Learning problem starts with data, such as a list of emails, posts, or tweets. Common sources of textual information include:</p><ul><li id="8e91">Product reviews (on Amazon, Yelp, and various App Stores)</li><li id="cadd">User-generated content (Tweets, Facebook posts, StackOverflow questions)</li><li id="e017">Troubleshooting (customer requests, support tickets, chat logs)</li></ul><p id="bb40"><strong>“Disasters on Social Media” dataset</strong></p><p id="851c">For this post, we will use a dataset generously provided by <a href="https://www.crowdflower.com/data-for-everyone/" target="_blank">CrowdFlower</a>, called “Disasters on Social Media”, where:</p><blockquote id="eca3">Contributors looked at over 10,000 tweets culled with a variety of searches like “ablaze”, “quarantine”, and “pandemonium”, then noted whether the tweet referred to a disaster event (as opposed to a joke with the word or a movie review or something non-disastrous).</blockquote><p id="82a2">Our task will be to detect which tweets are about a <strong>disastrous event</strong> as opposed to an <strong>irrelevant topic</strong> such as a movie. Why? A potential application would be to exclusively notify law enforcement officials about urgent emergencies while ignoring reviews of the most recent Adam Sandler film. A particular challenge with this task is that both classes contain the same search terms used to find the tweets, so we will have to use subtler differences to distinguish between them.</p><p id="d7ec">In the rest of this post, we will refer to tweets that are about disasters as “<strong>disaster</strong>”, and tweets about anything else as “<strong>irrelevant</strong>”.</p><h4 id="7fb7">Labels</h4><p id="e2d8">We have labeled data and so we know which tweets belong to which categories. As Richard Socher outlines below, it is usually faster, simpler, and cheaper to <strong>find and label enough data</strong> to train a model on, rather than trying to optimize a complex unsupervised method.</p><figure id="7677"><div><div><img src="https://cdn-images-1.medium.com/freeze/max/60/1*CdnxyA_fMXxEcEQ1kUTFRg.png?q=20" /><div class="readableLargeImageContainer"><img src="https://cdn-images-1.medium.com/max/1600/1*CdnxyA_fMXxEcEQ1kUTFRg.png" /></div></div></div><figcaption>Richard Socher’s pro-tip</figcaption></figure><h3 id="2a98">Step 2: Clean your data</h3><blockquote id="4a39">The number one rule we follow is: “Your model will only ever be as good as your data.”</blockquote><p id="05a8">One of the key skills of a data scientist is knowing whether the next step should be working on the model or the data. A good rule of thumb is to look at the data first and then clean it up. <strong>A clean dataset will allow a model to learn meaningful features and not overfit on irrelevant noise</strong><strong>.</strong></p><p id="ed00">Here is a checklist to use to clean your data: (see the <a href="https://github.com/hundredblocks/concrete_NLP_tutorial/blob/master/NLP_notebook.ipynb" target="_blank">code</a> for more details):</p><ol><li id="4f9b">Remove all irrelevant characters such as any non alphanumeric characters</li><li id="9b14"><a href="https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html" target="_blank">Tokenize</a> your text by separating it into individual words</li><li id="e441">Remove words that are not relevant, such as “@” twitter mentions or urls</li><li id="3b94">Convert all characters to lowercase, in order to treat words such as “hello”, “Hello”, and “HELLO” the same</li><li id="61d0">Consider combining misspelled or alternately spelled words to a single representation (e.g. “cool”/”kewl”/”cooool”)</li><li id="5ebc">Consider <a href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" target="_blank">lemmatization</a> (reduce words such as “am”, “are”, and “is” to a common form such as “be”)</li></ol><p id="6c30">After following these steps and checking for additional errors, we can start using the clean, labelled data to train models!</p><h3 id="4808">Step 3: Find a good data representation</h3><p id="bf8a">Machine Learning models take numerical values as input. Models working on images, for example, take in a matrix representing the intensity of each pixel in each color channel.</p><figure id="d8b3"><div><div><img src="https://cdn-images-1.medium.com/freeze/max/60/1*6pW5mPAxYhYBZxkc-hKf0A.png?q=20" /><div class="readableLargeImageContainer"><img src="https://cdn-images-1.medium.com/max/1600/1*6pW5mPAxYhYBZxkc-hKf0A.png" /></div></div></div><figcaption>A smiling face represented as a matrix of numbers.</figcaption></figure><p id="a538">Our dataset is a list of sentences, so in order for our algorithm to extract patterns from the data, we first need to find a way to represent it in a way that our algorithm can understand, i.e. as a list of numbers.</p><h4 id="8d9f">One-hot encoding (Bag of Words)</h4><p id="09e0">A natural way to represent text for computers is to encode each character individually as a number (<a href="https://en.wikipedia.org/wiki/ASCII" target="_blank">ASCII</a> for example). If we were to feed this simple representation into a classifier, it would have to learn the structure of words from scratch based only on our data, which is impossible for most datasets. We need to use a higher level approach.</p><p id="4c10">For example, we can build a <strong>vocabulary</strong> of all the unique words in our dataset, and associate a unique index to each word in the vocabulary. Each sentence is then represented as a list that is as long as the number of distinct words in our vocabulary. At each index in this list, we mark how many times the given word appears in our sentence. This is called a <a href="https://en.wikipedia.org/wiki/Bag-of-words_model" target="_blank"><strong>Bag of Words</strong></a><strong> model</strong>, since it is a representation that completely ignores the order of words in our sentence. This is illustrated below.</p><figure id="fa0b"><div><div><img src="https://cdn-images-1.medium.com/freeze/max/60/1*oQ3suk0Ayc8z8i1QIl5Big.png?q=20" /><div class="readableLargeImageContainer"><img src="https://cdn-images-1.medium.com/max/1600/1*oQ3suk0Ayc8z8i1QIl5Big.png" /></div></div></div><figcaption>Representing sentences as a Bag of Words. Sentences on the left, representation on the right. Each index in the vectors represent one particular word.</figcaption></figure><h4 id="ae55">Visualizing the embeddings</h4><p id="2ec8">We have around 20,000 words in our vocabulary in the “Disasters of Social Media” example, which means that every sentence will be represented as a vector of length 20,000. The vector will contain <strong>mostly 0s</strong> because each sentence contains only a very small subset of our vocabulary.</p><p id="6551">In order to see whether our embeddings are capturing information that is <strong>relevant to our problem</strong> (i.e. whether the tweets are about disasters or not), it is a good idea to visualize them and see if the classes look well separated. Since vocabularies are usually very large and visualizing data in 20,000 dimensions is impossible, techniques like <a href="https://en.wikipedia.org/wiki/Principal_component_analysis" target="_blank">PCA</a> will help project the data down to two dimensions. This is plotted below.</p><figure id="9063"><div><div><img src="https://cdn-images-1.medium.com/freeze/max/60/1*ikis3EFujlrmVk_JEQMvzQ.png?q=20" /><div class="readableLargeImageContainer"><img src="https://cdn-images-1.medium.com/max/1600/1*ikis3EFujlrmVk_JEQMvzQ.png" /></div></div></div><figcaption>Visualizing Bag of Words embeddings.</figcaption></figure><p id="72b1">The two classes do not look very well separated, which could be a feature of our embeddings or simply of our dimensionality reduction. In order to see whether the Bag of Words features are of any use, we can train a classifier based on them.</p><h3 id="671a">Step 4: Classification</h3><p id="92e2">When first approaching a problem, a general best practice is to start with the simplest tool that could solve the job. Whenever it comes to classifying data, a common favorite for its versatility and explainability is <a href="https://en.wikipedia.org/wiki/Logistic_regression" target="_blank">Logistic Regression</a>. It is very simple to train and the results are interpretable as you can easily extract the most important coefficients from the model.</p><p id="0386">We split our data in to a training set used to fit our model and a test set to see how well it generalizes to unseen data. After training, we get an <strong>accuracy of 75.4%. </strong>Not too shabby! Guessing the most frequent class (“irrelevant”) would give us only 57%. However, even if 75% precision was good enough for our needs, <strong>we should never ship a model without trying to understand it.</strong></p><h3 id="2dc1">Step 5: Inspection</h3><h4 id="5405">Confusion Matrix</h4><p id="8cef">A first step is to understand the types of errors our model makes, and which kind of errors are least desirable. In our example, <strong>false positives</strong> are classifying an irrelevant tweet as a disaster, and <strong>false negatives</strong> are classifying a disaster as an irrelevant tweet. If the priority is to react to every potential event, we would want to lower our false negatives. If we are constrained in resources however, we might prioritize a lower false positive rate to reduce false alarms. A good way to visualize this information is using a <a href="https://en.wikipedia.org/wiki/Confusion_matrix" target="_blank">Confusion Matrix</a>, which compares the predictions our model makes with the true label. Ideally, the matrix would be a diagonal line from top left to bottom right (our predictions match the truth perfectly).</p><figure id="46fd"><div><div><img src="https://cdn-images-1.medium.com/freeze/max/60/1*DicbwUOoqFezDWROfsZ-CQ.png?q=20" /><div class="readableLargeImageContainer"><img src="https://cdn-images-1.medium.com/max/1600/1*DicbwUOoqFezDWROfsZ-CQ.png" /></div></div></div><figcaption>Confusion Matrix (Green is a high proportion, blue is low)</figcaption></figure><p id="e3f3">Our classifier creates more false negatives than false positives (proportionally). In other words, our model’s most common error is inaccurately classifying disasters as irrelevant. If false positives represent a high cost for law enforcement, this could be a good bias for our classifier to have.</p><h4 id="23d1">Explaining and interpreting our model</h4><p id="be7c">To validate our model and interpret its predictions, it is important to look at which words it is using to make decisions. If our data is biased, our classifier will make accurate predictions in the sample data, but the model would not generalize well in the real world. Here we plot the <strong>most important words</strong> for both the disaster and irrelevant class. Plotting word importance is simple with Bag of Words and Logistic Regression, since we can just extract and rank the coefficients that the model used for its predictions.</p><figure id="7ed3"><div><div><img src="https://cdn-images-1.medium.com/freeze/max/60/1*UicK4XWFmF8mh0LL_fUJcA.png?q=20" /><div class="readableLargeImageContainer"><img src="https://cdn-images-1.medium.com/max/1600/1*UicK4XWFmF8mh0LL_fUJcA.png" /></div></div></div><figcaption>Bag of Words: Word importance</figcaption></figure><p id="dc4f">Our classifier correctly picks up on some patterns (hiroshima, massacre), but clearly seems to be overfitting on some meaningless terms (heyoo, x1392). Right now, our Bag of Words model is dealing with a huge vocabulary of different words and <strong>treating all words equally</strong>. However, some of these words are very frequent, and are only contributing noise to our predictions. Next, we will try a way to represent sentences that can account for the frequency of words, to see if we can pick up more signal from our data.</p><h3 id="425f">Step 6: Accounting for vocabulary structure</h3><h4 id="0c9f">TF-IDF</h4><p id="952b">In order to help our model focus more on meaningful words, we can use a <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" target="_blank">TF-IDF score</a> (Term Frequency, Inverse Document Frequency) on top of our Bag of Words model. TF-IDF weighs words by how rare they are in our dataset, discounting words that are too frequent and just add to the noise. Here is the PCA projection of our new embeddings.</p><figure id="523a"><div><div><img src="https://cdn-images-1.medium.com/freeze/max/60/1*wjD8-Cq009lMkRvfcVaW0w.png?q=20" /><div class="readableLargeImageContainer"><img src="https://cdn-images-1.medium.com/max/1600/1*wjD8-Cq009lMkRvfcVaW0w.png" /></div></div></div><figcaption>Visualizing TF-IDF embeddings.</figcaption></figure><p id="4dd4">We can see above that there is a clearer distinction between the two colors. This should make it easier for our classifier to separate both groups. Let’s see if this leads to better performance. Training another Logistic Regression on our new embeddings, we get <strong>an accuracy of 76.2%.</strong></p><p id="c970">A very slight improvement. Has our model started picking up on more important words? If we are getting a better result while preventing our model from “cheating” then we can truly consider this model an upgrade.</p><figure id="4099"><div><div><img src="https://cdn-images-1.medium.com/freeze/max/60/1*bdCuSrONh3dI6r8Xmzurcg.png?q=20" /><div class="readableLargeImageContainer"><img src="https://cdn-images-1.medium.com/max/1600/1*bdCuSrONh3dI6r8Xmzurcg.png" /></div></div></div><figcaption>TF-IDF: Word importance</figcaption></figure><p id="dea5">The words it picked up look much more relevant! Although our metrics on our test set only increased slightly, we have much more confidence in the terms our model is using, and thus would feel more comfortable deploying it in a system that would interact with customers.</p><h3 id="ca70">Step 7: Leveraging semantics</h3><h4 id="f445">Word2Vec</h4><p id="599f">Our latest model managed to pick up on high signal words. However, it is very likely that if we deploy this model, we will encounter words that we have not seen in our training set before. The previous model will not be able to accurately classify these tweets, <strong>even if it has seen very similar words during training</strong>.</p><p id="b23e">To solve this problem, we need to capture the <strong>semantic meaning of words</strong>, meaning we need to understand that words like ‘good’ and ‘positive’ are closer than ‘apricot’ and ‘continent.’ The tool we will use to help us capture meaning is called Word2Vec.</p><p id="0171"><strong>Using pre-trained words</strong></p><p id="5180"><a href="https://arxiv.org/abs/1301.3781" target="_blank">Word2Vec</a> is a technique to find continuous embeddings for words. It learns from reading massive amounts of text and memorizing which words tend to appear in similar contexts. After being trained on enough data, it generates a 300-dimension vector for each word in a vocabulary, with words of similar meaning being closer to each other.</p><p id="6c76">The authors of the <a href="https://arxiv.org/abs/1301.3781" target="_blank">paper</a> open sourced a model that was pre-trained on a very large corpus which we can leverage to include some knowledge of semantic meaning into our model. The pre-trained vectors can be found in the <a href="https://github.com/hundredblocks/concrete_NLP_tutorial" target="_blank">repository</a> associated with this post.</p><h4 id="86ed">Sentence level representation</h4><p id="9d62">A quick way to get a sentence embedding for our classifier is to average Word2Vec scores of all words in our sentence. This is a Bag of Words approach just like before, but this time <strong>we only lose the syntax of our sentence, while keeping some semantic information.</strong></p><figure id="ef23"><div><div><img src="https://cdn-images-1.medium.com/freeze/max/60/1*THo9NKchWkCAOILvs1eHuQ.png?q=20" /><div class="readableLargeImageContainer"><img src="https://cdn-images-1.medium.com/max/1600/1*THo9NKchWkCAOILvs1eHuQ.png" /></div></div></div><figcaption>Word2Vec sentence embedding</figcaption></figure><p id="82e9">Here is a visualization of our new embeddings using previous techniques:</p><figure id="7efb"><div><div><img src="https://cdn-images-1.medium.com/freeze/max/60/1*Dt66MaGpumPGxHfAwooieA.png?q=20" /><div class="readableLargeImageContainer"><img src="https://cdn-images-1.medium.com/max/1600/1*Dt66MaGpumPGxHfAwooieA.png" /></div></div></div><figcaption>Visualizing Word2Vec embeddings.</figcaption></figure><p id="8b9b">The two groups of colors look even more separated here, our new embeddings should help our classifier find the separation between both classes. After training the same model a third time (a Logistic Regression), we get <strong>an accuracy score of 77.7%</strong>, our best result yet! Time to inspect our model.</p><h4 id="3f73">The Complexity/Explainability trade-off</h4><p id="ff12">Since our embeddings are not represented as a vector with one dimension per word as in our previous models, it’s harder to see which words are the most relevant to our classification. While we still have access to the coefficients of our Logistic Regression, they relate to the 300 dimensions of our embeddings rather than the indices of words.</p><p id="8eb6">For such a low gain in accuracy, losing all explainability seems like a harsh trade-off. However, with more complex models we can leverage <strong>black box explainers</strong> such as <a href="https://arxiv.org/abs/1602.04938" target="_blank">LIME</a> in order to get some insight into how our classifier works.</p><p id="3234"><strong>LIME</strong></p><p id="7914">LIME is <a href="https://github.com/marcotcr/lime" target="_blank">available on Github</a> through an open-sourced package. A black-box explainer allows users to explain the decisions of any classifier <strong>on one particular example </strong>by perturbing the input (in our case removing words from the sentence) and seeing how the prediction changes.</p><p id="cc44">Let’s see a couple explanations for sentences from our dataset.</p><figure id="8b22"><div><div><img src="https://cdn-images-1.medium.com/freeze/max/60/1*w8zlZbHildSWpEWW_bBcAw.png?q=20" /><div class="readableLargeImageContainer"><img src="https://cdn-images-1.medium.com/max/1600/1*w8zlZbHildSWpEWW_bBcAw.png" /></div></div></div><figcaption>Correct disaster words are picked up to classify as “relevant”.</figcaption></figure><figure id="356f"><div><div><img src="https://cdn-images-1.medium.com/freeze/max/60/1*44zlmsnb-hENy0BXSsmzfg.png?q=20" /><div class="readableLargeImageContainer"><img src="https://cdn-images-1.medium.com/max/1600/1*44zlmsnb-hENy0BXSsmzfg.png" /></div></div></div><figcaption>Here, the contribution of the words to the classification seems less obvious.</figcaption></figure><p id="d8ed">However, we do not have time to explore the thousands of examples in our dataset. What we’ll do instead is run LIME on a representative sample of test cases and see which words keep coming up as strong contributors. Using this approach we can get word importance scores like we had for previous models and validate our model’s predictions.</p><figure id="da03"><div><div><img src="https://cdn-images-1.medium.com/freeze/max/60/1*YxFOFx_kxovglm_OLZD9Sw.png?q=20" /><div class="readableLargeImageContainer"><img src="https://cdn-images-1.medium.com/max/1600/1*YxFOFx_kxovglm_OLZD9Sw.png" /></div></div></div><figcaption>Word2Vec: Word importance</figcaption></figure><p id="5c17">Looks like the model picks up highly relevant words implying that it appears to make understandable decisions. These seem like the most relevant words out of all previous models and therefore we’re more comfortable deploying in to production.</p><h3 id="f99a">Step 8: Leveraging syntax using end-to-end approaches</h3><p id="9971">We’ve covered quick and efficient approaches to generate compact sentence embeddings. However, by omitting the order of words, we are discarding all of the syntactic information of our sentences. If these methods do not provide sufficient results, you can utilize more complex model that take in whole sentences as input and predict labels without the need to build an intermediate representation. A common way to do that is to treat a sentence as <strong>a sequence of individual word vectors</strong> using either Word2Vec or more recent approaches such as <a href="https://nlp.stanford.edu/projects/glove/" target="_blank">GloVe</a> or <a href="https://arxiv.org/abs/1708.00107" target="_blank">CoVe</a>. This is what we will do below.</p>